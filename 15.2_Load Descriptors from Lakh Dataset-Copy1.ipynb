{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load our own descriptors from the Lakh Dataset and perform Classification with scikit-learn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pretty_midi\n",
    "# import librosa\n",
    "import mir_eval\n",
    "import mir_eval.display\n",
    "import tables\n",
    "import IPython.display\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# Local path constants\n",
    "DATA_PATH = 'data'\n",
    "RESULTS_PATH = 'results'\n",
    "# Path to the file match_scores.json distributed with the LMD\n",
    "SCORE_FILE = os.path.join(RESULTS_PATH, 'match_scores.json')\n",
    "# The Tonnetze used for graph generation\n",
    "TONNETZEDICT = {'T129': [1, 2, 9], 'T147': [1, 4, 7], 'T237': [2, 3, 7], 'T345': [3, 4, 5]}\n",
    "# Define the labels we want to find (we can add or remove)\n",
    "LABELS = [\"classic\", \"rock\", \"pop\", \"folk\", \"metal\", \"jazz\", \"disco\"]\n",
    "\n",
    "# Utility functions for retrieving paths\n",
    "def msd_id_to_dirs(msd_id):\n",
    "    \"\"\"Given an MSD ID, generate the path prefix.\n",
    "    E.g. TRABCD12345678 -> A/B/C/TRABCD12345678\"\"\"\n",
    "    return os.path.join(msd_id[2], msd_id[3], msd_id[4], msd_id)\n",
    "\n",
    "def msd_id_to_mp3(msd_id):\n",
    "    \"\"\"Given an MSD ID, return the path to the corresponding mp3\"\"\"\n",
    "    return os.path.join(DATA_PATH, 'msd', 'mp3',\n",
    "                        msd_id_to_dirs(msd_id) + '.mp3')\n",
    "\n",
    "def msd_id_to_h5(h5):\n",
    "    \"\"\"Given an MSD ID, return the path to the corresponding h5\"\"\"\n",
    "    return os.path.join(RESULTS_PATH, 'lmd_matched_h5',\n",
    "                        msd_id_to_dirs(msd_id) + '.h5')\n",
    "\n",
    "def get_midi_path(msd_id, midi_md5, kind):\n",
    "    \"\"\"Given an MSD ID and MIDI MD5, return path to a MIDI file.\n",
    "    kind should be one of 'matched' or 'aligned'. \"\"\"\n",
    "    return os.path.join(RESULTS_PATH, 'lmd_{}'.format(kind),\n",
    "                        msd_id_to_dirs(msd_id), midi_md5 + '.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial Classification\n",
    "\n",
    "##### We try a graph kernel method by first reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                        | 0/31034 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-3-1eaae97066b4>\u001b[0m(26)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     23 \u001b[1;33m                \u001b[0myi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_graph_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mTonnetz\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".p\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;34m\"_label.p\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     24 \u001b[1;33m                \u001b[1;32mif\u001b[0m \u001b[0myi\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     25 \u001b[1;33m                    \u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 26 \u001b[1;33m                    \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     27 \u001b[1;33m                    \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> yi\n",
      "'rock'\n",
      "ipdb> c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                            | 1/31034 [00:20<174:57:21, 20.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-3-1eaae97066b4>\u001b[0m(25)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     23 \u001b[1;33m                \u001b[0myi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_graph_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mTonnetz\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".p\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;34m\"_label.p\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     24 \u001b[1;33m                \u001b[1;32mif\u001b[0m \u001b[0myi\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 25 \u001b[1;33m                    \u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     26 \u001b[1;33m                    \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     27 \u001b[1;33m                    \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> yi\n",
      "'pop'\n",
      "ipdb> file\n",
      "'c3da6699f64da3db8e523cbbaa80f384_graph_T147.p'\n",
      "ipdb> n\n",
      "> \u001b[1;32m<ipython-input-3-1eaae97066b4>\u001b[0m(26)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     23 \u001b[1;33m                \u001b[0myi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_graph_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mTonnetz\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".p\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;34m\"_label.p\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     24 \u001b[1;33m                \u001b[1;32mif\u001b[0m \u001b[0myi\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     25 \u001b[1;33m                    \u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 26 \u001b[1;33m                    \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     27 \u001b[1;33m                    \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Debugger\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "# Set the desirable Tonnetz\n",
    "Tonnetz = \"T147\"\n",
    "\n",
    "\n",
    "with open(SCORE_FILE) as f:\n",
    "    # The json SCORE_FILE is a dict of ids from Million Dollar\n",
    "    scores = json.load(f)\n",
    "y = list()\n",
    "G = list()\n",
    "for msd_id in tqdm(scores.keys()):\n",
    "    # open every directory with midi files and save file dir to var msd_dir\n",
    "    msd_dir = msd_id_to_dirs(msd_id)\n",
    "    # add the directory where graphs where saved\n",
    "    graph_directory =  os.path.join(RESULTS_PATH, \"lmd_graphs\", msd_dir)\n",
    "    # first check if the directory isn't empty\n",
    "    if os.listdir(graph_directory):\n",
    "        for file in os.listdir(graph_directory):\n",
    "            if file.endswith(Tonnetz+\".p\"):\n",
    "                Gi = pickle.load( open( os.path.join(graph_directory, file), \"rb\" ) )\n",
    "                yi = pickle.load( open( os.path.join(graph_directory, file.split(\"_graph_\" + Tonnetz + \".p\")[0]+ \"_label.p\"), \"rb\" ) )\n",
    "                if yi != None:\n",
    "                    set_trace()\n",
    "                    y.append(yi)\n",
    "                    G.append(Gi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 17490 labels\n",
      "and 17490 graphs\n",
      "classic has occurred 1111 times\n",
      "rock has occurred 6469 times\n",
      "pop has occurred 4714 times\n",
      "folk has occurred 413 times\n",
      "metal has occurred 524 times\n",
      "jazz has occurred 1917 times\n",
      "disco has occurred 1118 times\n",
      "other has occurred 1224 times\n"
     ]
    }
   ],
   "source": [
    "print(\"We have\", len(y), \"labels\")\n",
    "print(\"and\", len(G), \"graphs\")\n",
    "\n",
    "for label in LABELS+[\"other\"]:\n",
    "    print('{} has occurred {} times'.format(label, y.count(label)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from grakel.utils import graph_from_networkx\n",
    "\n",
    "# Transform networkx graphs to grakel representations\n",
    "G = list(graph_from_networkx(G, node_labels_tag='note'))\n",
    "\n",
    "# Splits the dataset into a training and a test set\n",
    "G_train, G_test, y_train, y_test = train_test_split(G, y, test_size=0.3, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.03%\n"
     ]
    }
   ],
   "source": [
    "from grakel.kernels import WeisfeilerLehman, GraphletSampling\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Uses the WEisfeilerLehman kernel to generate the kernel matrices\n",
    "gk = WeisfeilerLehman(n_iter=4, normalize=True)\n",
    "K_train = gk.fit_transform(G_train)\n",
    "K_test = gk.transform(G_test)\n",
    "\n",
    "# Uses the SVM classifier to perform classification\n",
    "clf = SVC(kernel=\"precomputed\")\n",
    "clf.fit(K_train, y_train)\n",
    "y_pred = clf.predict(K_test)\n",
    "\n",
    "# Computes and prints the classification accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", str(round(acc*100, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Classification Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clf_conf = plot_confusion_matrix(clf, K_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification via merging disconnected subgraphs into a Big Graph.\n",
    "\n",
    "Taking the disjoint union for all graphs per datapoint merging in a single big graph for classification via kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                        | 0/31034 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-2-777665a38689>\u001b[0m(43)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     41 \u001b[1;33m        \u001b[1;32mif\u001b[0m \u001b[0mIsGraphDir\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     42 \u001b[1;33m            \u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 43 \u001b[1;33m            \u001b[0mU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisjoint_union\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"T345\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisjoint_union\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"T129\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisjoint_union\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"T237\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"T147\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     44 \u001b[1;33m            \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     45 \u001b[1;33m            \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> yi\n",
      "'rock'\n",
      "ipdb> file\n",
      "'cd3b9c8bb118575bcd712cffdba85fce_label.p'\n",
      "ipdb> yi\n",
      "'rock'\n",
      "ipdb> yi\n",
      "'rock'\n",
      "ipdb> c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                            | 1/31034 [00:50<435:00:36, 50.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-2-777665a38689>\u001b[0m(42)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     40 \u001b[1;33m        \u001b[1;31m# the disjoint union of graphs (have to chek if a graph exists)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     41 \u001b[1;33m        \u001b[1;32mif\u001b[0m \u001b[0mIsGraphDir\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 42 \u001b[1;33m            \u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     43 \u001b[1;33m            \u001b[0mU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisjoint_union\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"T345\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisjoint_union\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"T129\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisjoint_union\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"T237\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"T147\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     44 \u001b[1;33m            \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> yi\n",
      "'pop'\n",
      "ipdb> c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                            | 2/31034 [01:03<339:25:48, 39.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-2-777665a38689>\u001b[0m(43)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     41 \u001b[1;33m        \u001b[1;32mif\u001b[0m \u001b[0mIsGraphDir\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     42 \u001b[1;33m            \u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 43 \u001b[1;33m            \u001b[0mU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisjoint_union\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"T345\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisjoint_union\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"T129\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisjoint_union\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"T237\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"T147\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     44 \u001b[1;33m            \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     45 \u001b[1;33m            \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> yi\n",
      "'rock'\n",
      "ipdb> file\n",
      "'ae4502a8dc4853d7efc9edb0c12f6682_label.p'\n",
      "ipdb> c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                      | 3/31034 [1:17:02<12024:49:53, 1395.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-2-777665a38689>\u001b[0m(42)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     40 \u001b[1;33m        \u001b[1;31m# the disjoint union of graphs (have to chek if a graph exists)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     41 \u001b[1;33m        \u001b[1;32mif\u001b[0m \u001b[0mIsGraphDir\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 42 \u001b[1;33m            \u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     43 \u001b[1;33m            \u001b[0mU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisjoint_union\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"T345\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisjoint_union\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"T129\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisjoint_union\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"T237\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"T147\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     44 \u001b[1;33m            \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> yi\n",
      "'pop'\n",
      "ipdb> file\n",
      "'db426aa15937ba4f477233ac2f72a13e_label.p'\n",
      "ipdb> graph_directory\n",
      "'results\\\\lmd_graphs\\\\D\\\\Z\\\\K\\\\TRDZKYG128F92E3640'\n"
     ]
    }
   ],
   "source": [
    "# Debugger\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "with open(SCORE_FILE) as f:\n",
    "    # The json SCORE_FILE is a dict of ids from Million Dollar\n",
    "    scores = json.load(f)\n",
    "y = list()\n",
    "Gi = dict()\n",
    "G = list()\n",
    "for msd_id in tqdm(scores.keys()):\n",
    "    # open every directory with midi files and save file dir to var msd_dir\n",
    "    msd_dir = msd_id_to_dirs(msd_id)\n",
    "    # add the directory where graphs where saved\n",
    "    graph_directory =  os.path.join(RESULTS_PATH, \"lmd_graphs\", msd_dir)\n",
    "    key = list(TONNETZEDICT.keys())\n",
    "    # first check if the directory isn't empty\n",
    "    if len(os.listdir(graph_directory))>1:\n",
    "        try: \n",
    "            for file in os.listdir(graph_directory):\n",
    "                IsGraphDir = False\n",
    "                if file.endswith(key[0] +\".p\"):\n",
    "                    Gi[key[0]] = pickle.load( open( os.path.join(graph_directory, file), \"rb\" ) )\n",
    "                    IsGraphDir = True\n",
    "                if file.endswith(key[1] +\".p\"):\n",
    "                    Gi[key[1]] = pickle.load( open( os.path.join(graph_directory, file), \"rb\" ) )\n",
    "                    IsGraphDir = True\n",
    "                if file.endswith(key[2] +\".p\"):\n",
    "                    Gi[key[2]] = pickle.load( open( os.path.join(graph_directory, file), \"rb\" ) )\n",
    "                    IsGraphDir = True\n",
    "                if file.endswith(key[3] +\".p\"):\n",
    "                    Gi[key[3]] = pickle.load( open( os.path.join(graph_directory, file), \"rb\" ) )\n",
    "                    IsGraphDir = True\n",
    "                if file.endswith(\"label.p\"):\n",
    "                    yi = pickle.load( open( os.path.join(graph_directory, file), \"rb\" ) )\n",
    "                    IsGraphDir = True\n",
    "        except:\n",
    "            IsGraphDir = False\n",
    "        # the disjoint union of graphs (have to chek if a graph exists)\n",
    "        if IsGraphDir:\n",
    "            set_trace()\n",
    "            U = nx.disjoint_union(Gi[\"T345\"], nx.disjoint_union(Gi[\"T129\"], nx.disjoint_union(Gi[\"T237\"], Gi[\"T147\"])))\n",
    "            G.append(U)\n",
    "            y.append(yi)\n",
    "            IsGraphDir = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 18796 labels\n",
      "and 18796 graphs\n",
      "classic has occurred 1392 times\n",
      "rock has occurred 7402 times\n",
      "pop has occurred 5140 times\n",
      "folk has occurred 269 times\n",
      "metal has occurred 701 times\n",
      "jazz has occurred 1443 times\n",
      "disco has occurred 1404 times\n",
      "other has occurred 1045 times\n"
     ]
    }
   ],
   "source": [
    "print(\"We have\", len(y), \"labels\")\n",
    "print(\"and\", len(G), \"graphs\")\n",
    "\n",
    "for label in LABELS+[\"other\"]:\n",
    "    print('{} has occurred {} times'.format(label, y.count(label)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melki\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\melki\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.datasets.lfw module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from grakel.utils import graph_from_networkx\n",
    "\n",
    "# Transform networkx graphs to grakel representations\n",
    "G = list(graph_from_networkx(G, node_labels_tag='note'))\n",
    "\n",
    "# Splits the dataset into a training and a test set\n",
    "G_train, G_test, y_train, y_test = train_test_split(G, y, test_size=0.3, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 39.48%\n"
     ]
    }
   ],
   "source": [
    "from grakel.kernels import WeisfeilerLehman, GraphletSampling\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Uses the WEisfeilerLehman kernel to generate the kernel matrices\n",
    "gk = WeisfeilerLehman(n_iter=4, normalize=True)\n",
    "K_train = gk.fit_transform(G_train)\n",
    "K_test = gk.transform(G_test)\n",
    "\n",
    "# Uses the SVM classifier to perform classification\n",
    "clf = SVC(kernel=\"precomputed\")\n",
    "clf.fit(K_train, y_train)\n",
    "y_pred = clf.predict(K_test)\n",
    "\n",
    "# Computes and prints the classification accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", str(round(acc*100, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification via Boosting\n",
    "\n",
    "In this section we apply the simple classification for every graph and the descriptors retrieved from the HMD5 files seperately and then we combine the results with a boosting learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SCORE_FILE) as f:\n",
    "    # The json SCORE_FILE is a dict of ids from Million Dollar\n",
    "    scores = json.load(f)\n",
    "y = { k : list() for k in TONNETZEDICT.keys()}\n",
    "G = { k : list() for k in TONNETZEDICT.keys()}\n",
    "for msd_id in tqdm(scores.keys()):\n",
    "    # open every directory with midi files and save file dir to var msd_dir\n",
    "    msd_dir = msd_id_to_dirs(msd_id)\n",
    "    # add the directory where graphs where saved\n",
    "    graph_directory =  os.path.join(RESULTS_PATH, \"lmd_graphs\", msd_dir)\n",
    "    # first check if the directory isn't empty\n",
    "    if os.listdir(graph_directory):\n",
    "        for key, tonnetz in TONNETZEDICT.items():\n",
    "            for file in os.listdir(graph_directory):\n",
    "                if file.endswith(key +\".p\"):\n",
    "                    Gi = pickle.load( open( os.path.join(graph_directory, file), \"rb\" ) )\n",
    "                    yi = pickle.load( open( os.path.join(graph_directory, file.split(\"_graph_\" +key+\".p\")[0]+ \"_label.p\"), \"rb\" ) )\n",
    "                    y[key].append(yi)\n",
    "                    G[key].append(Gi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from grakel.kernels import WeisfeilerLehman, GraphletSampling\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "G_train = dict()\n",
    "G_test = dict()\n",
    "K_train = dict() \n",
    "K_test = dict()\n",
    "clf = dict()\n",
    "y_pred = dict()\n",
    "\n",
    "for key in TONNETZEDICT.keys():  \n",
    "    # Transform networkx graphs to grakel representations\n",
    "    G[key] = list(graph_from_networkx(G[key], node_labels_tag='note'))\n",
    "    # do not shuffle the split\n",
    "    G_train[key], G_test[key], y_train, y_test = train_test_split(G[key], y[key], test_size=0.3, shuffle=False, stratify=y)\n",
    "    gk = WeisfeilerLehman(n_iter=1, normalize=True)\n",
    "    K_train[key] = gk.fit_transform(G_train[key])\n",
    "    K_test[key] = gk.transform(G_test[key])\n",
    "    y_pred[key] = clf[key].predict(K_test[key])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
