{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melki\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\melki\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.datasets.lfw module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from Tonnetz_Select import fromMidiToPCS as fmpc\n",
    "from Tonnetz_Select import analysisFromCorpus\n",
    "from TrajectoryCalculationsWithClass import NewTrajectory, TrajectoryLookBefore\n",
    "from graph_creation import createGrakel, createNX\n",
    "from FirstNotePosition import PlaceFirstNote\n",
    "from structural_functions import mergeDicts\n",
    "from Compliance_Function import complianceFunction\n",
    "import os\n",
    "from itertools import islice, groupby\n",
    "from operator import itemgetter\n",
    "import music21 as ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a graphs from corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def trajectory_calc(midifile, Tonnetz):\n",
    "#     chordList = \n",
    "#     trajectory = NewTrajectory(chordList, T345, PlaceFirstNote(chordList, Tonnetz))\n",
    "#     return trajectory\n",
    "    \n",
    "# def file_save_trajectories(directory):\n",
    "#     for file in directory :\n",
    "#         if file endswith \".mid\":\n",
    "#             for tonnetz in Tonnetze :\n",
    "#                 grakelgraph = trajectory_calc(file, tonnetz)\n",
    "#                 picklesave(grakelgraph, os.join(directory, file, tonnetz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = NewTrajectory([[0,4,7], [5, 9, 0], [2, 7, 11], [0,4,7]], [3, 4, 5], (0,0))\n",
    "graph = createNX(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (1, 0), (1, 1), (0, -1), (-1, -1), (2, 2), (2, 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<7x7 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 25 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(graph.nodes)\n",
    "import networkx as nx\n",
    "nx.adjacency_matrix(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GraphOfNewPiece(newPiece):\n",
    "    '''Build a graph Object from a midi file.'''\n",
    "    # extract the directory and the file extension from the piece\n",
    "    shortfilename = os.path.splitext(os.path.basename(newPiece))[0]\n",
    "    file = ms.corpus.parse(newPiece)\n",
    "    # apply full compliance function for corpus\n",
    "        # finds chordList and 2 Tonnetze\n",
    "    chordList, (Tonnetz1, Tonnetz2) = complianceFunction(file, \"Corpus\")\n",
    "    T345 = [3, 4, 5]\n",
    "    firstPoint = PlaceFirstNote(chordList, T345)\n",
    "    trajectory = NewTrajectory(chordList, T345, firstPoint)\n",
    "    graph = createGrakel(trajectory)\n",
    "#     graph.addName(shortfilename)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetWorksByComposer(composerName):\n",
    "    listOfGraphs = []\n",
    "    target = []\n",
    "#     composer, style, harmony = inputQuestions()\n",
    "    listofWorks = ms.corpus.getComposer(composerName)\n",
    "    for piece in listofWorks[0:60]:\n",
    "#         print(\"Building Trajectory for \", piece)\n",
    "        graph = GraphOfNewPiece(piece)\n",
    "        listOfGraphs.append(graph)\n",
    "        target.append(composerName)\n",
    "\n",
    "    return target, listOfGraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "61\n",
      "61\n",
      "71\n",
      "84\n",
      "67\n",
      "91\n",
      "107\n",
      "66\n",
      "120\n",
      "73\n",
      "94\n",
      "70\n",
      "70\n",
      "55\n",
      "69\n",
      "68\n",
      "59\n",
      "83\n",
      "89\n",
      "94\n",
      "96\n",
      "45\n",
      "50\n",
      "87\n",
      "68\n",
      "166\n",
      "77\n",
      "88\n",
      "64\n",
      "78\n",
      "55\n",
      "91\n",
      "70\n",
      "66\n",
      "70\n",
      "76\n",
      "91\n",
      "63\n",
      "85\n",
      "74\n",
      "57\n",
      "92\n",
      "69\n",
      "180\n",
      "53\n",
      "63\n",
      "54\n",
      "36\n",
      "62\n",
      "84\n",
      "76\n",
      "64\n",
      "81\n",
      "83\n",
      "94\n",
      "63\n",
      "153\n",
      "97\n",
      "55\n",
      "405\n",
      "228\n",
      "190\n",
      "120\n",
      "302\n",
      "146\n",
      "392\n",
      "215\n",
      "257\n",
      "150\n",
      "170\n",
      "116\n",
      "84\n",
      "54\n",
      "143\n",
      "100\n",
      "129\n",
      "71\n",
      "327\n",
      "142\n",
      "205\n",
      "118\n",
      "405\n",
      "229\n",
      "122\n",
      "183\n",
      "95\n",
      "367\n",
      "139\n",
      "321\n",
      "136\n",
      "367\n",
      "199\n",
      "363\n",
      "189\n",
      "432\n",
      "212\n",
      "167\n",
      "60\n",
      "119\n",
      "73\n",
      "292\n",
      "117\n",
      "213\n",
      "113\n",
      "248\n",
      "82\n",
      "187\n",
      "98\n",
      "455\n",
      "151\n",
      "342\n",
      "133\n",
      "262\n",
      "66\n",
      "248\n",
      "169\n",
      "140\n",
      "88\n",
      "133\n",
      "198\n",
      "208\n",
      "180\n",
      "267\n",
      "149\n",
      "169\n",
      "208\n",
      "173\n",
      "185\n",
      "166\n",
      "216\n",
      "200\n",
      "182\n",
      "221\n",
      "186\n",
      "214\n",
      "182\n",
      "202\n",
      "179\n",
      "215\n",
      "137\n",
      "169\n",
      "186\n",
      "160\n",
      "229\n",
      "168\n",
      "150\n",
      "238\n",
      "191\n",
      "190\n",
      "195\n",
      "250\n",
      "197\n",
      "190\n",
      "220\n",
      "206\n",
      "199\n",
      "201\n",
      "207\n",
      "161\n",
      "149\n",
      "206\n",
      "215\n",
      "193\n",
      "245\n",
      "209\n",
      "203\n",
      "205\n",
      "147\n",
      "162\n",
      "181\n",
      "127\n",
      "177\n",
      "185\n",
      "185\n",
      "188\n",
      "205\n",
      "214\n",
      "181\n",
      "205\n"
     ]
    }
   ],
   "source": [
    "from grakel.utils import graph_from_networkx\n",
    "y1, G1 = GetWorksByComposer(\"bach\")\n",
    "y2, G2 = GetWorksByComposer(\"monteverdi\")\n",
    "y3, G3 = GetWorksByComposer(\"palestrina\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def pickleSave(listOfGraphs, listOfLabels, saveName) :\n",
    "    completeName = \"Comparison_Results/\"+ saveName + \".p\"\n",
    "    with open(completeName, 'wb') as config_dictionary_file:\n",
    "      # Step 3\n",
    "      pickle.dump([listOfGraphs, listOfLabels], config_dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickleSave(G1, y1, \"bach\")\n",
    "pickleSave(G2, y2, \"monteverdi\")\n",
    "pickleSave(G3, y3, \"palestrina\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDict(file_name) :\n",
    "    complete_name = 'Comparison_Results/' + file_name + '.p'\n",
    "    graphDict = pickle.load( open( complete_name, \"rb\" ) )\n",
    "    return graphDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "G = loadDict(\"bach\")[0] + loadDict(\"palestrina\")[0] + loadDict(\"monteverdi\")[0]\n",
    "# X = []\n",
    "# for graph in G:\n",
    "#     # we return the nx graph from the custom graph object\n",
    "#     X.append(graph.graph)\n",
    "\n",
    "y = loadDict(\"bach\")[1] + loadDict(\"palestrina\")[1] + loadDict(\"monteverdi\")[1]\n",
    "# G_train_nx = X[3:17]\n",
    "# G_test_nx = X[0:3] + X[17:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Splits the dataset into a training and a test set\n",
    "G_train, G_test, y_train, y_test = train_test_split(G, y, test_size=0.3, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.52%\n"
     ]
    }
   ],
   "source": [
    "from grakel.utils import graph_from_networkx\n",
    "from grakel.kernels import WeisfeilerLehman, GraphletSampling\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Uses the shortest path kernel to generate the kernel matrices\n",
    "gk = WeisfeilerLehman(n_iter=1, normalize=True)\n",
    "K_train = gk.fit_transform(G_train)\n",
    "K_test = gk.transform(G_test)\n",
    "\n",
    "# Uses the SVM classifier to perform classification\n",
    "clf = SVC(kernel=\"precomputed\")\n",
    "clf.fit(K_train, y_train)\n",
    "y_pred = clf.predict(K_test)\n",
    "\n",
    "# Computes and prints the classification accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", str(round(acc*100, 2)) + \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.0%\n"
     ]
    }
   ],
   "source": [
    "from grakel.kernels import GraphletSampling\n",
    "\n",
    "# Uses the shortest path kernel to generate the kernel matrices\n",
    "gk = GraphletSampling(normalize=True, verbose=True)\n",
    "K_train = gk.fit_transform(G_train)\n",
    "K_test = gk.transform(G_test)\n",
    "\n",
    "# Uses the SVM classifier to perform classification\n",
    "clf = SVC(kernel=\"precomputed\")\n",
    "clf.fit(K_train, y_train)\n",
    "y_pred = clf.predict(K_test)\n",
    "\n",
    "# Computes and prints the classification accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", str(round(acc*100, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRANDOM FORREST CLASSIFIER : \n",
      "\n",
      "Classification Report : \n",
      "\n",
      "\u001b[0m               precision    recall  f1-score   support\n",
      "\n",
      "        bach       0.33      0.06      0.10        18\n",
      "  monteverdi       0.48      0.83      0.61        18\n",
      "  palestrina       0.60      0.67      0.63        18\n",
      "\n",
      "    accuracy                           0.52        54\n",
      "   macro avg       0.47      0.52      0.45        54\n",
      "weighted avg       0.47      0.52      0.45        54\n",
      " \n",
      "\n",
      "\u001b[1mConfusion Matrix : \n",
      "\n",
      "\u001b[0m [[ 1 11  6]\n",
      " [ 1 15  2]\n",
      " [ 1  5 12]] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print('\\033[1m' + 'RANDOM FORREST CLASSIFIER : \\n\\n' + 'Classification Report : \\n\\n'\n",
    "+ '\\033[0m', classification_report(y_test, y_pred), '\\n\\n' \n",
    "+ '\\033[1m' + 'Confusion Matrix : \\n\\n'\n",
    "+ '\\033[0m', confusion_matrix(y_test, y_pred), '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
