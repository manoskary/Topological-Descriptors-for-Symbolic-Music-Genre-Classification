{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification (Composer Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv # create csv\n",
    "import pandas as pd # Open and manage CSV files\n",
    "import pickle # Open python objects\n",
    "import os # Directory Control\n",
    "import seaborn # easy plots\n",
    "from itertools import product\n",
    "import warnings # find and don't show warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets load our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDicts(directory):\n",
    "    '''Search for .p pickle objects in subdirectories of a file.'''\n",
    "    subDir = [x[0] for x in os.walk(directory)]\n",
    "    graphList = []\n",
    "    for i, subfolder in enumerate(subDir[1:]):\n",
    "        graphs = []\n",
    "        for file in os.listdir(subfolder):\n",
    "            if file.endswith(\".p\") :\n",
    "                complete_name = subfolder + '/' + file\n",
    "                print('Rendering --> ', file)\n",
    "                picklegraphs = pickle.load(open(complete_name, \"rb\"))\n",
    "                for pair in picklegraphs:\n",
    "                    graphs.append(pair)\n",
    "        graphList.append(graphs)\n",
    "    return graphList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write2csv(directory, file_name,  data):\n",
    "    '''Write data to a .csv file.'''\n",
    "    directory = directory + '/' + file_name + '.csv'\n",
    "    with open(directory, 'w') as csvFile:\n",
    "        writer = csv.writer(csvFile)\n",
    "        writer.writerows(data)\n",
    "    csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCSVfiles(graphList):\n",
    "    for i, graphs1 in enumerate(graphList):\n",
    "        if i!=7:\n",
    "            for j, graphs2 in enumerate(graphList[i+1:]):\n",
    "                graphs = graphs1 + graphs2\n",
    "                values = [['Composer', 'Kalz Centrality 1', 'Kalz Centrality 2', 'Global Clustering 1', 'Global Clustering 2', 'Square Clustering 1', 'Square Clustering 2', 'Harmonic Centrality 1', 'Harmonic Centrality 2', 'Closeness Centrality 1', 'Closeness Centrality 2', 'Tonnetz 1', 'Tonnetz 2']]\n",
    "                composer = ''\n",
    "                for graph in graphs:\n",
    "                    graph1, graph2 = graph\n",
    "                    values.append([graph1.composer, graph1.kalz_coef, graph2.kalz_coef, graph1.glob_clust_coef, graph2.glob_clust_coef, graph1.square_clustering_coef, graph2.square_clustering_coef, graph1.harmonic_coef, graph2.harmonic_coef, graph1.closeness_coef, graph2.closeness_coef, graph1.trajectory.Tonnetz, graph2.trajectory.Tonnetz])\n",
    "                write2csv('Comparison_Results/binary_classification', str(i)+str(j+i+1), values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encodingData(data) :\n",
    "    label_quality = LabelEncoder()\n",
    "    data = label_quality.fit_transform(data)\n",
    "    return label_quality, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropingData(data, label2Drop):\n",
    "    data = data.drop(columns=label2Drop)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "def separateDataset(data, label):\n",
    "    X = data.drop(label, axis=1)\n",
    "    y = data[label]\n",
    "    return X, y\n",
    "\n",
    "def splitDataset(data, label):\n",
    "    X, y = separateDataset(data, label)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, stratify=y)\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savePrints(string2output):\n",
    "    complete_directory = 'Comparison_Results/binary_classification/results.txt'\n",
    "    file = open(complete_directory,\"w\")\n",
    "    file.write(string2output)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def applyRandomForest(data, label):\n",
    "    X_train, y_train, X_test, y_test = splitDataset(data, label)\n",
    "    rfc = RandomForestClassifier(n_estimators=1000, criterion=\"entropy\")\n",
    "    rfc.fit(X_train, y_train)\n",
    "    pred_rfc = rfc.predict(X_test)\n",
    "\n",
    "    return \"%.2f\" % round(f1_score(y_test, pred_rfc, average='weighted'), 2)\n",
    "\n",
    "def applykNN(data, label):\n",
    "    X_train, y_train, X_test, y_test = splitDataset(data, label)\n",
    "    knn = KNeighborsClassifier(n_neighbors=10)\n",
    "    knn.fit(X_train, y_train)\n",
    "    pred_knn = knn.predict(X_test)\n",
    "\n",
    "    return \"%.2f\" % round(f1_score(y_test, pred_knn, average='weighted'), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BinaryPredictions(directory):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        # Do stuff here\n",
    "        \n",
    "        print('\\033[1m' + 'BINARY CLASSIFICATION \\n\\n')\n",
    "        print('\\033[0m' + '| Composers | Score | Notes |')\n",
    "        print('| -----------------------------------| --------------- |----------------------------------------|')\n",
    "        for file in os.listdir(directory):\n",
    "            if file.endswith('.csv'):\n",
    "                complete_name = directory + '/' + file\n",
    "                data = pd.read_csv(complete_name, sep = ',')\n",
    "                data['Tonnetz 1'] = encodingData(data['Tonnetz 1'])[1]\n",
    "                data['Tonnetz 2'] = encodingData(data['Tonnetz 2'])[1]\n",
    "                label_quality, data['Composer'] = encodingData(data['Composer'])\n",
    "                composers = label_quality.inverse_transform([0])[0] + ' vs ' + label_quality.inverse_transform([1])[0]\n",
    "                score = applyRandomForest(data, 'Composer')\n",
    "                notes = 'RF'\n",
    "                print('| ', composers , ' | ', score, ' | ', notes , ' | ')\n",
    "                score = applykNN(data,'Composer')\n",
    "                notes = 'kNN'\n",
    "                print('| ', composers , ' | ', score, ' | ', notes , ' | ')\n",
    "#                 score = applyRandomForest(dropingData(data, 'Harmonic Centrality'), 'Composer')\n",
    "#                 notes = 'Wihout Harmonic Centrality'\n",
    "#                 print('| ', composers , ' | ', score, ' | ', notes , ' | ')\n",
    "#                 score = applyRandomForest(dropingData(data, 'Closeness Centrality'), 'Composer')\n",
    "#                 notes = 'Wihout Closeness Centrality'\n",
    "#                 print('| ', composers , ' | ', score, ' | ', notes , ' | ')\n",
    "#                 score = applyRandomForest(dropingData(data, 'Kalz Centrality'), 'Composer')\n",
    "#                 notes = 'Wihout Kalz Centrality'\n",
    "#                 print('| ', composers , ' | ', score, ' | ', notes , ' | ')\n",
    "#                 score = applyRandomForest(dropingData(data, 'Global Clustering'), 'Composer')\n",
    "#                 notes = 'Wihout Global Clustering'\n",
    "#                 print('| ', composers , ' | ', score, ' | ', notes , ' | ')\n",
    "#                 score = applyRandomForest(dropingData(data, 'Square Clustering'), 'Composer')\n",
    "#                 notes = 'Wihout Square Clustering'\n",
    "#                 print('| ', composers , ' | ', score, ' | ', notes , ' | ')\n",
    "#                 score = applyRandomForest(dropingData(data, 'Tonnetz'), 'Composer')\n",
    "#                 notes = 'Wihout Tonnetz'\n",
    "#                 print('| ', composers , ' | ', score, ' | ', notes , ' | ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering -->  bach.p\n",
      "Rendering -->  beethoven.p\n",
      "Rendering -->  beethovenCorpus.p\n",
      "Rendering -->  chopin.p\n",
      "Rendering -->  chopinCorpus.p\n",
      "Rendering -->  haydn_quartets.p\n",
      "Rendering -->  jazz.p\n",
      "Rendering -->  monteverdi.p\n",
      "Rendering -->  mozart.p\n",
      "Rendering -->  mozartCorpus.p\n",
      "Rendering -->  mozart_quartets.p\n",
      "Rendering -->  palestrina.p\n",
      "Rendering -->  schumann.p\n",
      "Rendering -->  schumannCorpus.p\n",
      "\u001b[1mBINARY CLASSIFICATION \n",
      "\n",
      "\n",
      "\u001b[0m| Composers | Score | Notes |\n",
      "| -----------------------------------| --------------- |----------------------------------------|\n",
      "|  bach vs beethoven  |  1.00  |  RF  | \n",
      "|  bach vs beethoven  |  0.97  |  kNN  | \n",
      "|  bach vs chopin  |  0.97  |  RF  | \n",
      "|  bach vs chopin  |  0.94  |  kNN  | \n",
      "|  bach vs haydn  |  0.89  |  RF  | \n",
      "|  bach vs haydn  |  0.93  |  kNN  | \n",
      "|  Unknown vs bach  |  1.00  |  RF  | \n",
      "|  Unknown vs bach  |  0.98  |  kNN  | \n",
      "|  bach vs monteverdi  |  0.83  |  RF  | \n",
      "|  bach vs monteverdi  |  0.69  |  kNN  | \n",
      "|  bach vs mozart  |  1.00  |  RF  | \n",
      "|  bach vs mozart  |  0.98  |  kNN  | \n",
      "|  bach vs palestrina  |  0.83  |  RF  | \n",
      "|  bach vs palestrina  |  0.75  |  kNN  | \n",
      "|  bach vs schumann  |  0.87  |  RF  | \n",
      "|  bach vs schumann  |  0.92  |  kNN  | \n",
      "|  beethoven vs chopin  |  0.80  |  RF  | \n",
      "|  beethoven vs chopin  |  0.77  |  kNN  | \n",
      "|  beethoven vs haydn  |  0.92  |  RF  | \n",
      "|  beethoven vs haydn  |  0.84  |  kNN  | \n",
      "|  Unknown vs beethoven  |  0.98  |  RF  | \n",
      "|  Unknown vs beethoven  |  0.89  |  kNN  | \n",
      "|  beethoven vs monteverdi  |  0.95  |  RF  | \n",
      "|  beethoven vs monteverdi  |  0.95  |  kNN  | \n",
      "|  beethoven vs mozart  |  0.80  |  RF  | \n",
      "|  beethoven vs mozart  |  0.78  |  kNN  | \n",
      "|  beethoven vs palestrina  |  0.98  |  RF  | \n",
      "|  beethoven vs palestrina  |  0.98  |  kNN  | \n",
      "|  beethoven vs schumann  |  0.84  |  RF  | \n",
      "|  beethoven vs schumann  |  0.84  |  kNN  | \n",
      "|  chopin vs haydn  |  0.63  |  RF  | \n",
      "|  chopin vs haydn  |  0.59  |  kNN  | \n",
      "|  Unknown vs chopin  |  0.97  |  RF  | \n",
      "|  Unknown vs chopin  |  0.82  |  kNN  | \n",
      "|  chopin vs monteverdi  |  0.81  |  RF  | \n",
      "|  chopin vs monteverdi  |  0.83  |  kNN  | \n",
      "|  chopin vs mozart  |  0.61  |  RF  | \n",
      "|  chopin vs mozart  |  0.68  |  kNN  | \n",
      "|  chopin vs palestrina  |  0.97  |  RF  | \n",
      "|  chopin vs palestrina  |  0.86  |  kNN  | \n",
      "|  chopin vs schumann  |  0.46  |  RF  | \n",
      "|  chopin vs schumann  |  0.46  |  kNN  | \n",
      "|  Unknown vs haydn  |  0.92  |  RF  | \n",
      "|  Unknown vs haydn  |  0.97  |  kNN  | \n",
      "|  haydn vs monteverdi  |  0.84  |  RF  | \n",
      "|  haydn vs monteverdi  |  0.89  |  kNN  | \n",
      "|  haydn vs mozart  |  0.72  |  RF  | \n",
      "|  haydn vs mozart  |  0.68  |  kNN  | \n",
      "|  haydn vs palestrina  |  0.88  |  RF  | \n",
      "|  haydn vs palestrina  |  0.91  |  kNN  | \n",
      "|  haydn vs schumann  |  0.63  |  RF  | \n",
      "|  haydn vs schumann  |  0.54  |  kNN  | \n",
      "|  Unknown vs monteverdi  |  0.95  |  RF  | \n",
      "|  Unknown vs monteverdi  |  0.98  |  kNN  | \n",
      "|  Unknown vs mozart  |  0.95  |  RF  | \n",
      "|  Unknown vs mozart  |  0.93  |  kNN  | \n",
      "|  Unknown vs palestrina  |  1.00  |  RF  | \n",
      "|  Unknown vs palestrina  |  0.98  |  kNN  | \n",
      "|  Unknown vs schumann  |  0.98  |  RF  | \n",
      "|  Unknown vs schumann  |  0.91  |  kNN  | \n",
      "|  monteverdi vs mozart  |  0.91  |  RF  | \n",
      "|  monteverdi vs mozart  |  0.89  |  kNN  | \n",
      "|  monteverdi vs palestrina  |  0.75  |  RF  | \n",
      "|  monteverdi vs palestrina  |  0.81  |  kNN  | \n",
      "|  monteverdi vs schumann  |  0.82  |  RF  | \n",
      "|  monteverdi vs schumann  |  0.72  |  kNN  | \n",
      "|  mozart vs palestrina  |  0.91  |  RF  | \n",
      "|  mozart vs palestrina  |  0.86  |  kNN  | \n",
      "|  mozart vs schumann  |  0.68  |  RF  | \n",
      "|  mozart vs schumann  |  0.60  |  kNN  | \n"
     ]
    }
   ],
   "source": [
    "createCSVfiles(loadDicts('Comparison_Results/binary_classification'))\n",
    "\n",
    "BinaryPredictions('Comparison_Results/binary_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
